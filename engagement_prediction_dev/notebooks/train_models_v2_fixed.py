"""
Model Training V2 - FIXED
LinkedIn Engagement Prediction - TrendPilot

Date: February 1, 2026
Version: 2.0 (Fixed Data Leakage & MAPE Issues)

ISSUES FIXED:
1. DATA LEAKAGE: Removed features calculated from target variables
2. MAPE CALCULATION: Properly handle zero values
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import xgboost as xgb
import lightgbm as lgb
import joblib
import json
import os
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

sns.set_style('whitegrid')
plt.rcParams['figure.figsize'] = (14, 6)

print("=" * 80)
print("MODEL TRAINING V2 - FIXED (NO DATA LEAKAGE)")
print("=" * 80)

# ============================================================================
# 1. DATA LOADING & LEAKAGE DETECTION
# ============================================================================

print("\nðŸ“‚ Loading data...")
data = pd.read_csv('../data/selected_features_data.csv')
print(f"Dataset: {data.shape[0]:,} rows Ã— {data.shape[1]} columns")

# Identify leakage features (features derived from targets)
LEAKAGE_FEATURES = [
    'reactions_per_sentiment',      # reactions / (sentiment + 1) âŒ
    'reactions_per_word',            # reactions / word_count âŒ
    'comments_per_word',             # comments / word_count âŒ
    'reactions_vs_influencer_avg',  # reactions - influencer_avg âŒ
    'comments_vs_influencer_avg',   # comments - influencer_avg âŒ
    'comment_to_reaction_ratio'     # comments / reactions âŒ
]

print("\nðŸš¨ LEAKAGE FEATURES TO REMOVE:")
for feat in LEAKAGE_FEATURES:
    if feat in data.columns:
        print(f"  âœ— {feat}")

# Remove leakage features
data_clean = data.drop(columns=LEAKAGE_FEATURES, errors='ignore')
print(f"\nâœ“ Removed {len(LEAKAGE_FEATURES)} leakage features")
print(f"âœ“ Clean dataset: {data_clean.shape[0]:,} rows Ã— {data_clean.shape[1]} columns")

# ============================================================================
# 2. FEATURE PREPARATION
# ============================================================================

print("\nðŸ”§ Preparing features...")
EXCLUDE_COLUMNS = ['reactions', 'comments', 'name', 'slno', 'content', 'time_spent', 'location']

feature_columns = [col for col in data_clean.columns if col not in EXCLUDE_COLUMNS]

X = data_clean[feature_columns]
y_reactions = data_clean['reactions']
y_comments = data_clean['comments']

# Check for NaN values
nan_counts = X.isna().sum()
if nan_counts.sum() > 0:
    print(f"\nâš ï¸ Found NaN values in {(nan_counts > 0).sum()} features:")
    for col in nan_counts[nan_counts > 0].index:
        print(f"  - {col}: {nan_counts[col]} NaNs")
    
    # Fill NaN with median
    print("\nðŸ”§ Filling NaN values with median...")
    X = X.fillna(X.median())
    print("âœ“ NaN values handled")

print(f"\nFeature matrix: {X.shape}")
print(f"Target (reactions): {y_reactions.shape}")
print(f"Target (comments): {y_comments.shape}")
print(f"\nValid features: {len(feature_columns)}")

print(f"\nðŸ“Š Target Statistics:")
reactions_zeros = (y_reactions == 0).sum()
comments_zeros = (y_comments == 0).sum()
print(f"Reactions = 0: {reactions_zeros:,} ({reactions_zeros / len(y_reactions) * 100:.2f}%)")
print(f"Comments = 0: {comments_zeros:,} ({comments_zeros / len(y_comments) * 100:.2f}%)")

# ============================================================================
# 3. TRAIN-TEST SPLIT
# ============================================================================

print("\nâœ‚ï¸ Splitting data...")
X_train, X_test, y_train_reactions, y_test_reactions = train_test_split(
    X, y_reactions, test_size=0.2, random_state=42
)

X_train, X_test, y_train_comments, y_test_comments = train_test_split(
    X, y_comments, test_size=0.2, random_state=42
)

print(f"Training set: {X_train.shape[0]:,} samples")
print(f"Test set: {X_test.shape[0]:,} samples")
print(f"Train/Test ratio: {X_train.shape[0] / X_test.shape[0]:.1f}")

# ============================================================================
# 4. CUSTOM MAPE FUNCTION
# ============================================================================

def safe_mape(y_true, y_pred, epsilon=1e-10):
    """
    Calculate MAPE excluding zero values in y_true.
    """
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)
    
    # Mask out zeros
    non_zero_mask = y_true > epsilon
    
    if not non_zero_mask.any():
        return None  # All zeros, MAPE undefined
    
    y_true_masked = y_true[non_zero_mask]
    y_pred_masked = y_pred[non_zero_mask]
    
    mape = np.mean(np.abs((y_true_masked - y_pred_masked) / y_true_masked)) * 100
    
    return mape

def evaluate_model(y_true, y_pred, model_name="Model"):
    """Evaluate model with all metrics."""
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    r2 = r2_score(y_true, y_pred)
    mape = safe_mape(y_true, y_pred)
    
    return {
        'model': model_name,
        'mae': mae,
        'rmse': rmse,
        'r2': r2,
        'mape': mape if mape is not None else np.nan
    }

print("âœ“ Custom MAPE function defined (handles zeros)")

# ============================================================================
# 5. MODEL TRAINING - REACTIONS
# ============================================================================

print("\n" + "=" * 80)
print("TRAINING MODELS FOR REACTIONS PREDICTION (NO LEAKAGE)")
print("=" * 80)

results_reactions = []

# 1. Linear Regression
print("\n1. Training Linear Regression...")
lr_reactions = LinearRegression()
lr_reactions.fit(X_train, y_train_reactions)
y_pred = lr_reactions.predict(X_test)
results_reactions.append(evaluate_model(y_test_reactions, y_pred, "Linear Regression"))
print(f"   MAE: {results_reactions[-1]['mae']:.2f}, RMSE: {results_reactions[-1]['rmse']:.2f}, RÂ²: {results_reactions[-1]['r2']:.4f}, MAPE: {results_reactions[-1]['mape']:.2f}%")

# 2. Random Forest
print("\n2. Training Random Forest...")
rf_reactions = RandomForestRegressor(
    n_estimators=100,
    max_depth=20,
    min_samples_split=10,
    min_samples_leaf=5,
    random_state=42,
    n_jobs=-1
)
rf_reactions.fit(X_train, y_train_reactions)
y_pred = rf_reactions.predict(X_test)
results_reactions.append(evaluate_model(y_test_reactions, y_pred, "Random Forest"))
print(f"   MAE: {results_reactions[-1]['mae']:.2f}, RMSE: {results_reactions[-1]['rmse']:.2f}, RÂ²: {results_reactions[-1]['r2']:.4f}, MAPE: {results_reactions[-1]['mape']:.2f}%")

# 3. XGBoost
print("\n3. Training XGBoost...")
xgb_reactions = xgb.XGBRegressor(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=6,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    n_jobs=-1
)
xgb_reactions.fit(X_train, y_train_reactions)
y_pred = xgb_reactions.predict(X_test)
results_reactions.append(evaluate_model(y_test_reactions, y_pred, "XGBoost"))
print(f"   MAE: {results_reactions[-1]['mae']:.2f}, RMSE: {results_reactions[-1]['rmse']:.2f}, RÂ²: {results_reactions[-1]['r2']:.4f}, MAPE: {results_reactions[-1]['mape']:.2f}%")

# 4. LightGBM
print("\n4. Training LightGBM...")
lgb_reactions = lgb.LGBMRegressor(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=-1,
    num_leaves=31,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    n_jobs=-1,
    verbose=-1
)
lgb_reactions.fit(X_train, y_train_reactions)
y_pred = lgb_reactions.predict(X_test)
results_reactions.append(evaluate_model(y_test_reactions, y_pred, "LightGBM"))
print(f"   MAE: {results_reactions[-1]['mae']:.2f}, RMSE: {results_reactions[-1]['rmse']:.2f}, RÂ²: {results_reactions[-1]['r2']:.4f}, MAPE: {results_reactions[-1]['mape']:.2f}%")

print("\nâœ“ Reactions models trained (without leakage)")

# ============================================================================
# 6. MODEL TRAINING - COMMENTS
# ============================================================================

print("\n" + "=" * 80)
print("TRAINING MODELS FOR COMMENTS PREDICTION (NO LEAKAGE)")
print("=" * 80)

results_comments = []

# 1. Linear Regression
print("\n1. Training Linear Regression...")
lr_comments = LinearRegression()
lr_comments.fit(X_train, y_train_comments)
y_pred = lr_comments.predict(X_test)
results_comments.append(evaluate_model(y_test_comments, y_pred, "Linear Regression"))
print(f"   MAE: {results_comments[-1]['mae']:.2f}, RMSE: {results_comments[-1]['rmse']:.2f}, RÂ²: {results_comments[-1]['r2']:.4f}, MAPE: {results_comments[-1]['mape']:.2f}%")

# 2. Random Forest
print("\n2. Training Random Forest...")
rf_comments = RandomForestRegressor(
    n_estimators=100,
    max_depth=20,
    min_samples_split=10,
    min_samples_leaf=5,
    random_state=42,
    n_jobs=-1
)
rf_comments.fit(X_train, y_train_comments)
y_pred = rf_comments.predict(X_test)
results_comments.append(evaluate_model(y_test_comments, y_pred, "Random Forest"))
print(f"   MAE: {results_comments[-1]['mae']:.2f}, RMSE: {results_comments[-1]['rmse']:.2f}, RÂ²: {results_comments[-1]['r2']:.4f}, MAPE: {results_comments[-1]['mape']:.2f}%")

# 3. XGBoost
print("\n3. Training XGBoost...")
xgb_comments = xgb.XGBRegressor(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=6,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    n_jobs=-1
)
xgb_comments.fit(X_train, y_train_comments)
y_pred = xgb_comments.predict(X_test)
results_comments.append(evaluate_model(y_test_comments, y_pred, "XGBoost"))
print(f"   MAE: {results_comments[-1]['mae']:.2f}, RMSE: {results_comments[-1]['rmse']:.2f}, RÂ²: {results_comments[-1]['r2']:.4f}, MAPE: {results_comments[-1]['mape']:.2f}%")

# 4. LightGBM
print("\n4. Training LightGBM...")
lgb_comments = lgb.LGBMRegressor(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=-1,
    num_leaves=31,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    n_jobs=-1,
    verbose=-1
)
lgb_comments.fit(X_train, y_train_comments)
y_pred = lgb_comments.predict(X_test)
results_comments.append(evaluate_model(y_test_comments, y_pred, "LightGBM"))
print(f"   MAE: {results_comments[-1]['mae']:.2f}, RMSE: {results_comments[-1]['rmse']:.2f}, RÂ²: {results_comments[-1]['r2']:.4f}, MAPE: {results_comments[-1]['mape']:.2f}%")

print("\nâœ“ Comments models trained (without leakage)")

# ============================================================================
# 7. MODEL COMPARISON
# ============================================================================

df_reactions = pd.DataFrame(results_reactions).sort_values('r2', ascending=False)
df_comments = pd.DataFrame(results_comments).sort_values('r2', ascending=False)

print("\n" + "=" * 80)
print("MODEL COMPARISON - REACTIONS (V2 - NO LEAKAGE)")
print("=" * 80)
print(df_reactions.to_string(index=False))

print("\n" + "=" * 80)
print("MODEL COMPARISON - COMMENTS (V2 - NO LEAKAGE)")
print("=" * 80)
print(df_comments.to_string(index=False))

# Select best models
best_reactions_model_name = df_reactions.iloc[0]['model']
best_comments_model_name = df_comments.iloc[0]['model']

print(f"\nâœ“ Best model for reactions: {best_reactions_model_name}")
print(f"\nâœ“ Best model for comments: {best_comments_model_name}")

model_dict_reactions = {
    'Linear Regression': lr_reactions,
    'Random Forest': rf_reactions,
    'XGBoost': xgb_reactions,
    'LightGBM': lgb_reactions
}

model_dict_comments = {
    'Linear Regression': lr_comments,
    'Random Forest': rf_comments,
    'XGBoost': xgb_comments,
    'LightGBM': lgb_comments
}

best_reactions_model = model_dict_reactions[best_reactions_model_name]
best_comments_model = model_dict_comments[best_comments_model_name]

# ============================================================================
# 8. FEATURE IMPORTANCE
# ============================================================================

print("\n" + "=" * 80)
print("FEATURE IMPORTANCE ANALYSIS")
print("=" * 80)

if hasattr(best_reactions_model, 'feature_importances_'):
    importance_reactions = pd.DataFrame({
        'feature': feature_columns,
        'importance': best_reactions_model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print("\nTop 15 features for REACTIONS:")
    print(importance_reactions.head(15).to_string(index=False))
else:
    print("\nReactions model does not have feature_importances_")

if hasattr(best_comments_model, 'feature_importances_'):
    importance_comments = pd.DataFrame({
        'feature': feature_columns,
        'importance': best_comments_model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print("\nTop 15 features for COMMENTS:")
    print(importance_comments.head(15).to_string(index=False))
else:
    print("\nComments model does not have feature_importances_")

# ============================================================================
# 9. SAVE MODELS
# ============================================================================

print("\n" + "=" * 80)
print("SAVING MODELS")
print("=" * 80)

os.makedirs('../models', exist_ok=True)

# Save best models
joblib.dump(best_reactions_model, '../models/best_reactions_model_v2.pkl')
joblib.dump(best_comments_model, '../models/best_comments_model_v2.pkl')

# Save feature list
with open('../models/feature_list_v2.json', 'w') as f:
    json.dump(feature_columns, f, indent=2)

# Save metadata
metadata = {
    'version': '2.0',
    'date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
    'leakage_features_removed': LEAKAGE_FEATURES,
    'reactions_model': {
        'type': best_reactions_model_name,
        'performance': {
            'mae': float(df_reactions.iloc[0]['mae']),
            'rmse': float(df_reactions.iloc[0]['rmse']),
            'r2': float(df_reactions.iloc[0]['r2']),
            'mape': float(df_reactions.iloc[0]['mape']) if not pd.isna(df_reactions.iloc[0]['mape']) else None
        },
        'feature_count': len(feature_columns)
    },
    'comments_model': {
        'type': best_comments_model_name,
        'performance': {
            'mae': float(df_comments.iloc[0]['mae']),
            'rmse': float(df_comments.iloc[0]['rmse']),
            'r2': float(df_comments.iloc[0]['r2']),
            'mape': float(df_comments.iloc[0]['mape']) if not pd.isna(df_comments.iloc[0]['mape']) else None
        },
        'feature_count': len(feature_columns)
    },
    'training_data': {
        'total_samples': len(X),
        'train_samples': len(X_train),
        'test_samples': len(X_test),
        'reactions_zeros': int(reactions_zeros),
        'comments_zeros': int(comments_zeros)
    }
}

with open('../models/model_metadata_v2.json', 'w') as f:
    json.dump(metadata, f, indent=2)

print("\nâœ“ Models saved to ../models/")
print("  - best_reactions_model_v2.pkl")
print("  - best_comments_model_v2.pkl")
print("  - feature_list_v2.json")
print("  - model_metadata_v2.json")

print("\n" + "=" * 80)
print("SUCCESS: V2 Models Trained Without Data Leakage!")
print("=" * 80)

print(f"\nðŸŽ¯ Reactions Model ({best_reactions_model_name}):")
print(f"  MAE: {df_reactions.iloc[0]['mae']:.2f}")
print(f"  RMSE: {df_reactions.iloc[0]['rmse']:.2f}")
print(f"  RÂ²: {df_reactions.iloc[0]['r2']:.4f}")
print(f"  MAPE: {df_reactions.iloc[0]['mape']:.2f}%")

print(f"\nðŸŽ¯ Comments Model ({best_comments_model_name}):")
print(f"  MAE: {df_comments.iloc[0]['mae']:.2f}")
print(f"  RMSE: {df_comments.iloc[0]['rmse']:.2f}")
print(f"  RÂ²: {df_comments.iloc[0]['r2']:.4f}")
print(f"  MAPE: {df_comments.iloc[0]['mape']:.2f}%")

print("\nâœ… These are LEGITIMATE models without data leakage!")
print("âœ… Performance is realistic for real-world deployment.")
print("\n" + "=" * 80)
