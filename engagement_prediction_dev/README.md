# Engagement Prediction Model Development

This folder contains all scripts, notebooks, and artifacts for developing machine learning models to predict LinkedIn post engagement (reactions and comments).

## üìÅ Project Structure

```
engagement_prediction_dev/
‚îú‚îÄ‚îÄ notebooks/            # Jupyter notebooks for complete pipeline
‚îÇ   ‚îú‚îÄ‚îÄ 01_data_loading_cleaning.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_text_preprocessing.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_feature_engineering.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 04_feature_selection_encoding.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 05_baseline_models.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 06_tree_models.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 07_advanced_models.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 08_model_comparison.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 09_model_evaluation.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 10_error_analysis.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 11_model_interpretation.ipynb
‚îÇ
‚îú‚îÄ‚îÄ reports/              # Detailed justification reports for each step
‚îÇ   ‚îú‚îÄ‚îÄ 01_data_loading_cleaning_REPORT.md
‚îÇ   ‚îú‚îÄ‚îÄ 02_text_preprocessing_REPORT.md
‚îÇ   ‚îú‚îÄ‚îÄ 03_feature_engineering_REPORT.md
‚îÇ   ‚îú‚îÄ‚îÄ 04_feature_selection_encoding_REPORT.md
‚îÇ   ‚îú‚îÄ‚îÄ 05_baseline_models_REPORT.md
‚îÇ   ‚îú‚îÄ‚îÄ 06_tree_models_REPORT.md
‚îÇ   ‚îú‚îÄ‚îÄ 08_model_comparison_REPORT.md
‚îÇ   ‚îú‚îÄ‚îÄ 09_model_evaluation_REPORT.md
‚îÇ   ‚îú‚îÄ‚îÄ 10_error_analysis_REPORT.md
‚îÇ   ‚îî‚îÄ‚îÄ 11_model_interpretation_REPORT.md
‚îÇ
‚îú‚îÄ‚îÄ data/                 # Processed datasets
‚îÇ   ‚îú‚îÄ‚îÄ cleaned_data.csv
‚îÇ   ‚îú‚îÄ‚îÄ preprocessed_data.csv
‚îÇ   ‚îú‚îÄ‚îÄ feature_engineered_data.csv
‚îÇ   ‚îú‚îÄ‚îÄ model_ready_data.csv
‚îÇ   ‚îú‚îÄ‚îÄ train_split.csv
‚îÇ   ‚îú‚îÄ‚îÄ val_split.csv
‚îÇ   ‚îî‚îÄ‚îÄ test_split.csv
‚îÇ
‚îú‚îÄ‚îÄ models/               # Trained model artifacts
‚îÇ   ‚îú‚îÄ‚îÄ reactions_model_v1.pkl
‚îÇ   ‚îú‚îÄ‚îÄ comments_model_v1.pkl
‚îÇ   ‚îú‚îÄ‚îÄ scaler.pkl
‚îÇ   ‚îú‚îÄ‚îÄ encoder.pkl
‚îÇ   ‚îî‚îÄ‚îÄ feature_config.json
‚îÇ
‚îú‚îÄ‚îÄ results/              # Evaluation results and reports
‚îÇ   ‚îú‚îÄ‚îÄ baseline_results.json
‚îÇ   ‚îú‚îÄ‚îÄ tree_model_results.json
‚îÇ   ‚îú‚îÄ‚îÄ model_comparison_report.html
‚îÇ   ‚îú‚îÄ‚îÄ evaluation_report.html
‚îÇ   ‚îî‚îÄ‚îÄ feature_importance_charts.png
‚îÇ
‚îú‚îÄ‚îÄ MODEL_DEVELOPMENT_PLAN.md  # Comprehensive development plan
‚îú‚îÄ‚îÄ requirements_model.txt      # Python dependencies
‚îî‚îÄ‚îÄ README.md                   # This file
```

## üéØ Objective

Build two separate regression models:
1. **Reactions Model**: Predict number of likes/reactions
2. **Comments Model**: Predict number of comments

## üìä Dataset

- **Source**: Kaggle - LinkedIn Influencers Data
- **Size**: 34,012 posts from 69 influencers
- **Target Variables**: reactions (100% complete), comments (100% complete)
- **Key Features**: content text, media_type, hashtags, followers

## üîß Setup

### 1. Create Virtual Environment
```bash
python -m venv venv_model_dev
source venv_model_dev/bin/activate  # On Windows: venv_model_dev\Scripts\activate
```

### 2. Install Dependencies
```bash
pip install -r requirements_model.txt
```

### 3. Download NLP Models
```bash
python -m spacy download en_core_web_sm
python -m nltk.downloader punkt stopwords wordnet vader_lexicon
```

## üöÄ Quick Start

### Development Approach

**We use Jupyter Notebooks for the entire pipeline**, NOT Python scripts. Each notebook:
- Contains detailed comments explaining each operation
- Includes markdown sections with rationale and justifications
- Shows visualizations with interpretations
- Generates a comprehensive report documenting decisions

### Notebook Execution

```bash
# Step 1: Data loading and cleaning
jupyter notebook notebooks/01_data_loading_cleaning.ipynb
# Output: data/cleaned_data.csv + reports/01_data_loading_cleaning_REPORT.md

# Step 2: Text preprocessing
jupyter notebook notebooks/02_text_preprocessing.ipynb
# Output: data/preprocessed_data.csv + reports/02_text_preprocessing_REPORT.md

# Step 3: Feature engineering
jupyter notebook notebooks/03_feature_engineering.ipynb
# Output: data/feature_engineered_data.csv + reports/03_feature_engineering_REPORT.md

# Step 4: Feature selection and encoding
jupyter notebook notebooks/04_feature_selection_encoding.ipynb
# Output: data/model_ready_data.csv + reports/04_feature_selection_encoding_REPORT.md

# Step 5: Train baseline models
jupyter notebook notebooks/05_baseline_models.ipynb
# Output: results/baseline_results.json + reports/05_baseline_models_REPORT.md

# Step 6: Train tree-based models
jupyter notebook notebooks/06_tree_models.ipynb
# Output: models/*.pkl + reports/06_tree_models_REPORT.md

# Step 7: Model comparison
jupyter notebook notebooks/08_model_comparison.ipynb
# Output: results/model_comparison_report.html + reports/08_model_comparison_REPORT.md

# Step 8: Evaluate best models
jupyter notebook notebooks/09_model_evaluation.ipynb
# Output: results/evaluation_report.html + reports/09_model_evaluation_REPORT.md
```

### Report Requirements

Each step produces a detailed Markdown report that includes:
- **Rationale**: Why each decision was made
- **Alternatives Considered**: What other approaches were evaluated
- **Justifications**: Statistical and business reasoning
- **Trade-offs**: Pros and cons of chosen approach
- **Results**: Quantitative outcomes and quality metrics
- **Recommendations**: Next steps and improvements

## üìà Features

### Base Formula Features (from base_score_calculation.txt)
- Content length categories and scores
- Hook pattern detection (12+ types)
- Power pattern detection (15+ types)
- Media type encoding
- Link penalties
- Promotional content detection

### Advanced NLP Features
- Sentiment analysis (polarity, subjectivity)
- Named Entity Recognition (persons, orgs, locations)
- Topic modeling labels
- Readability metrics (Flesch, Gunning Fog)
- Text statistics (sentence count, unique words, etc.)
- Engagement trigger patterns

### Derived Features
- Influencer-level statistics
- Engagement rates
- Content quality scores
- Virality potential scores

## üéØ Model Performance Goals

### Reactions Model
- **Minimum**: R¬≤ > 0.50
- **Target**: R¬≤ > 0.65
- **Stretch**: R¬≤ > 0.75

### Comments Model
- **Minimum**: R¬≤ > 0.40
- **Target**: R¬≤ > 0.55
- **Stretch**: R¬≤ > 0.65

## üìù Development Workflow

### Notebook Documentation Standards

All notebooks must include:

1. **Markdown Headers**: Clear section titles with explanations
2. **Code Comments**: Inline comments for complex operations
3. **Rationale Sections**: Explain WHY decisions were made
4. **Visualizations**: Charts with interpretations
5. **Statistical Summaries**: Metrics with business context
6. **Decision Justifications**: Document alternatives considered

### Timeline

1. **Data Preparation** (Week 1)
   - Clean and validate data (Notebook 01)
   - Preprocess text (Notebook 02)
   - Engineer NLP features (Notebook 03)
   - Select and encode features (Notebook 04)
   - **Deliverables**: 4 notebooks + 4 detailed reports

2. **Model Development** (Week 2)
   - Train baseline models (Notebook 05)
   - Train tree-based models (Notebook 06)
   - Compare models (Notebook 08)
   - **Deliverables**: 3 notebooks + 3 detailed reports

3. **Evaluation** (Week 3)
   - Performance analysis (Notebook 09)
   - Error analysis (Notebook 10)
   - Model interpretation with SHAP (Notebook 11)
   - **Deliverables**: 3 notebooks + 3 detailed reports

4. **Integration** (Week 4)
   - Create prediction API
   - Integrate with Streamlit app
   - Final documentation

## üîç Key Insights from EDA

‚úÖ **Strengths**:
- Complete reactions/comments data (100%)
- Rich content text (94.1% available)
- Good data quality overall (86.7% complete)

‚ö†Ô∏è **Limitations**:
- Views data completely missing (100%)
- Timestamps are relative, not absolute
- Cannot optimize for posting time

## üìö References

- [MODEL_DEVELOPMENT_PLAN.md](MODEL_DEVELOPMENT_PLAN.md) - Comprehensive development plan
- [../eda/eda_report.txt](../eda/eda_report.txt) - EDA findings
- [base_score_calculation.txt](base_score_calculation.txt) - Existing scoring algorithm

## üë• Contributors

TrendPilot Team - Capstone Project 2026

## üìÑ License

MIT License
